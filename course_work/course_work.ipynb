{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек и скриптов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбрал Statlog (German Credit Data) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SouthGermanCredit.asc\", sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. сделать feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К полям:\n",
    "-  применим OHE-кодирование\n",
    "- laufzeit, hoehe, alter - standardScaler\n",
    "- gastarb, telef, pers оставим пока как есть, laufkont, moral, verw, sparkont, beszeit, rate, famges, buerge, wohnzeit, verm, weitkred, wohn, bishkred, beruf тоже оставим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data.iloc[:,:-1]\n",
    "y_data = data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "base_cols = ['laufkont', 'moral', 'verw', 'sparkont', 'beszeit', 'rate', 'famges', 'buerge', 'wohnzeit',\n",
    "              'verm', 'weitkred', 'wohn', 'bishkred', 'beruf']\n",
    "continuos_cols = ['laufzeit', 'hoehe', 'alter']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "    \n",
    "# for cat_col in cat_cols:\n",
    "#     cat_transformer = Pipeline([\n",
    "#                 ('selector', ColumnSelector(key=cat_col)),\n",
    "#                 ('ohe', OHEEncoder(key=cat_col))\n",
    "#             ])\n",
    "#     cat_transformers.append((cat_col, cat_transformer))\n",
    "    \n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь объединим все наши трансформеры с помощью FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23159172e+00,  1.79151936e+00, -8.22306639e-01, ...,\n",
       "         2.00000000e+00,  1.00000000e+00,  3.00000000e+00],\n",
       "       [ 2.56154007e-01, -4.31285795e-01,  1.64371630e-01, ...,\n",
       "         2.00000000e+00,  1.00000000e+00,  3.00000000e+00],\n",
       "       [ 2.20702943e+00,  1.14226114e+00,  2.13772817e+00, ...,\n",
       "         1.00000000e+00,  1.00000000e+00,  3.00000000e+00],\n",
       "       ...,\n",
       "       [-1.36957551e+00, -6.34335662e-01,  6.12861752e-01, ...,\n",
       "         2.00000000e+00,  3.00000000e+00,  2.00000000e+00],\n",
       "       [-1.20700256e+00,  1.26581000e+00,  8.81955825e-01, ...,\n",
       "         2.00000000e+00,  2.00000000e+00,  4.00000000e+00],\n",
       "       [ 2.56154007e-01,  3.10483659e-03,  7.46736053e-02, ...,\n",
       "         2.00000000e+00,  1.00000000e+00,  4.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feats = FeatureUnion(continuos_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. обучить любой классификатор (какой вам нравится)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обучения модели и расчета метрик\n",
    "def get_metrics(classifier):\n",
    "    \n",
    "    #запустим кросс-валидацию\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "\n",
    "    #обучим пайплайн на всем тренировочном датасете\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_score = classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_params = {\n",
    "    'eval_metric': 'F1',\n",
    "    'auto_class_weights': 'Balanced',\n",
    "    'silent': True,\n",
    "    'one_hot_max_size': 20,\n",
    "    'early_stopping_rounds': 50,\n",
    "    'boosting_type': 'Ordered',\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "\n",
    "classifier_4 = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', CatBoostClassifier(\n",
    "    **frozen_params,\n",
    "    depth=4,\n",
    "    iterations=400,\n",
    "    learning_rate=0.1,\n",
    "    l2_leaf_reg=2.5,\n",
    "    bagging_temperature=1.5\n",
    ")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(classifier_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверяем качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoostClassifier показывает лучший рез-т по precision, согласно условиям задачи \"It is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).\" рез-т по precision более важен чем рез-т по recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features',\n",
       "  FeatureUnion(transformer_list=[('laufzeit',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='laufzeit')),\n",
       "                                                  ('standard',\n",
       "                                                   StandardScaler())])),\n",
       "                                 ('hoehe',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='hoehe')),\n",
       "                                                  ('standard',\n",
       "                                                   StandardScaler())])),\n",
       "                                 ('alter',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='alter')),\n",
       "                                                  ('standard',\n",
       "                                                   StandardScaler())])),\n",
       "                                 ('laufkont',\n",
       "                                  Pipe...\n",
       "                                 ('verm',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='verm'))])),\n",
       "                                 ('weitkred',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='weitkred'))])),\n",
       "                                 ('wohn',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='wohn'))])),\n",
       "                                 ('bishkred',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='bishkred'))])),\n",
       "                                 ('beruf',\n",
       "                                  Pipeline(steps=[('selector',\n",
       "                                                   NumberSelector(key='beruf'))]))])),\n",
       " ('classifier', <catboost.core.CatBoostClassifier at 0x7f848a3a7d60>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_4.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"german_credit_data_pipeline.dill\", \"wb\") as f:\n",
    "    dill.dump(classifier_4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save test\n",
    "X_test.to_csv(\"X_test.csv\", index=None)\n",
    "y_test.to_csv(\"y_test.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
